---
title: "Data 621 Homework 1"
author: "Critical Thinking Group 3: Vyannna Hill, Jose Rodriguez, and Christian Uriostegui"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r message=FALSE, include=FALSE}
library(tidyverse)
library(ggpubr)
library(corrplot)
library(mice)


training_set<-read_csv("https://raw.githubusercontent.com/Vy4thewin/criticalthinking3/main/moneyball-training-data.csv")
test_set<-read_csv("https://raw.githubusercontent.com/Vy4thewin/criticalthinking3/main/moneyball-evaluation-data.csv")
```

### Introduction of the MoneyBall game statistics from 1871 to 2006

For this analysis, the task assigned is when the next big win for the team based on their historical data. Let's review their statistical performance. The training data set was provided below for this exploration.

#### Data Exploration 

The initial review of the data set, the team saw on average 80 wins in a season. Their most prolific season saw 146 wins. One path of preemptive checks on normality is to view the binomial distribution of the team's wins. 
The wins distribution appears normally distributed, which is a good candidate for a linear regression model. There is a slight dip in density around 70 wins, which could reveal a issue in the unprocessed data set. Let's review possible predictors relationship with the team's wins

```{r include=FALSE}
#Let's review our training set and if the training set needs updates before its process
summary(training_set)

#review distribution of the response variable, see if not bi-modal 
ggplot(data=training_set,aes(x=TARGET_WINS))+geom_density()+theme_classic()
```


Two possible predictor values where selected for visualization of their relationship with the number of wins. The Walks by Batter and the Home runs by Batter. There is a flag of concern with both variables as it appears both predictor create a narrow linear tunnel. This can be influence by another variables. 

```{r}
#Visually checking for a positive linear trend with a singular predictor value
g<-ggplot(training_set,aes(x=TEAM_BATTING_BB,y=TARGET_WINS))+geom_point()+labs(title = "Teams Wins vs Walks by Batter",x="Walks by Batter",y="# of wins")+theme_classic()

# plotting the wins vs home runs
g1<-ggplot(training_set,aes(x=TEAM_BATTING_HR,y=TARGET_WINS))+geom_point()+labs(title = "Teams Wins vs Home runs by Batter",x="# of Homeruns",y="# of wins")+theme_classic()

#Viewing multiple graphs with a selected predictor variable and its response (wins)
ggarrange(g,g1,ncol = 2,nrow = 1)

```

When we further examine the data set, we noticed a few columns have a large amount of NA values. The largest unaccounted amount of values fall with batters hit by the pitchers. We do not have insight from the survey team if these NAs reflected no values recorded or a human imputation error. This will have to be sorted for the analysis. 

```{r include=FALSE}
#See the number of NAs per columns. Noticed Batters hit per pitch has the highest count
colSums(is.na(training_set))

```


### Preparing the game stats data set for regression |
#### Data preparation

From the previous part, there is no notation that NAs reflect zeros for the data set. 

There's two path for handling NAs. First path uses MICE to predict the missing values in the data set. The first step is to remove predictors that passed the threshold of randomness of missing values, as this method is under the assumption that values are missing at random. The two predictors "TEAM_BASERUN_CS" and "TEAM_BATTING_HBP" have a large amount of missing values, which is a strong indication its NAs are not missing at random. It is best to remove the predictors before running the MICE model on the data set. After its removal, the new data set can run through the model and have its values predict.

The other method is complete removal of the NAs. This methods all NAs from the original data set with only rows that are complete. This method does include all predictors but greatly reduces the data set by 90%+. This is not ideal as the number of observations greatly influences the model's regression.

```{r message=FALSE, warning=FALSE, include=FALSE}
#Way 1| to handle NAs, Drop predictor HBP and CS from the data set as missing and use MICE for imputation
#Let's select the lasso norm method for our imputation as its relates back to the week's reading
train.c1<-training_set%>%select(-c(INDEX,TEAM_BATTING_HBP,TEAM_BASERUN_CS))
train.c1<-complete(mice(train.c1,method = "lasso.norm",seed = 333))


#Noticed there are entries with NAs values that cannot be replaced with a formula. These entries will be removed from the training_set to prevent a inaccurate model
train.c2<-na.omit(training_set)

#remove the index column as it does not a have effect in the data
train.c2<-train.c2%>%select(-c(INDEX))


#Selecting v1 of the imputation data set
train.clean<-train.c1

#see data set reduction
c<-191
c<-((c-2200)/2200)*100
sprintf("The newest data set was reduced by %.02f%% from the original",c)
summary(train.clean)


#Seeing the correlation between non-NA predictors to indicate mutli-collinearity 
corrplot(cor(train.clean[,2:14]),method = "number",type="lower", tl.srt = .71,number.cex=0.75)


```


Although our observations was significantly reduced, it did open the possibility of new predictors. The MLB^[https://www.mlb.com/glossary/advanced-stats] and other baseball fanatic sites^[http://hosted.stats.com/mlb/stats.asp?file=glossary] provides a list of advanced statistics which expands the amount of available predictors. The new predictors introduced to clean data set are Strikeouts to walk "STW Ratio" and Total Bases.

*New Baseball Variables
  +STW Ratio: The times a pitcher strikeouts over the times a batter walks to first base
  +Total Bases: Number of bases gain by batter by hits


```{r include=FALSE}
# Found some baseball formulas here to add onto our analysis
#STW= pitchers strikeouts/ walks by batter
train.clean<-train.clean %>% mutate(STW_Ratio=TEAM_PITCHING_SO/TEAM_BATTING_BB)

#total bases=[H + 2B + (2 X 3B) + (3 X HR)].
train.clean<-train.clean%>%mutate(TB=TEAM_BATTING_H+TEAM_BATTING_2B+(2*TEAM_BATTING_3B)+(3*TEAM_BATTING_HR))

#two observations had NAs
train.clean<-na.omit(train.clean)

#review new columns
head(train.clean,3)
```

Let's scale our new training set before our analysis as the new variables are not on the same scale. Now, the training set is ready to be fitted!
```{r warning=FALSE, include=FALSE}
#see any possible predictors for skeweness and apply transformations before fitting 
g1<-ggplot(data=train.clean,aes(x=TEAM_BATTING_H))+geom_density()+theme_classic()
g2<-ggplot(data=train.clean,aes(x=TEAM_BATTING_2B))+geom_density()+theme_classic()
g3<-ggplot(data=train.clean,aes(x=TEAM_BATTING_3B))+geom_density()+theme_classic()
g4<-ggplot(data=train.clean,aes(x=TEAM_BATTING_HR))+geom_density()+theme_classic()
g5<-ggplot(data=train.clean,aes(x=TEAM_BATTING_BB))+geom_density()+theme_classic()
g6<-ggplot(data=train.clean,aes(x=TEAM_BATTING_SO))+geom_density()+theme_classic()
g7<-ggplot(data=train.clean,aes(x=TEAM_BASERUN_SB))+geom_density()+theme_classic()
g8<-ggplot(data=train.clean,aes(x=TEAM_PITCHING_H))+geom_density()+theme_classic()
g9<-ggplot(data=train.clean,aes(x=TEAM_PITCHING_HR))+geom_density()+theme_classic()
g10<-ggplot(data=train.clean,aes(x=TEAM_PITCHING_BB))+geom_density()+theme_classic()
g11<-ggplot(data=train.clean,aes(x=TEAM_PITCHING_SO))+geom_density()+theme_classic()
g12<-ggplot(data=train.clean,aes(x=TEAM_FIELDING_E))+geom_density()+theme_classic()
g13<-ggplot(data=train.clean,aes(x=TEAM_FIELDING_DP))+geom_density()+theme_classic()
g14<-ggplot(data=train.clean,aes(x=STW_Ratio))+geom_density()+theme_classic()
g16<-ggplot(data=train.clean,aes(x=TB))+geom_density()+theme_classic()
ggarrange(g1,g2,g3,g4,g5,g6,g7,g8,g9,g10,g11,g12,g13,g14,g16,ncol = 4,nrow = 4)

#only 2b appears to be normal, let's fixed the variables that are positively skewed with a log10 
#columns 15,12,8 cannot be transformed as some instances have negative numbers
train.clean<-train.clean%>%mutate_at(c(2,9,11,13,14),~log10(.))


#scale the training set so its easier for the system to process the data in the regression model
train_set<-scale(train.clean)
train_set <- data.frame(train_set)
```


### Selecting the predictor values for our model| BUILD MODELS 

Now we're going to create three linear models with distinct predictor values, and compare the results. For our first model, we're going assign see the affects of all the stats against *TARGET_WINS* 
```{r}
#first model using all baseball stats
fit1 = lm(TARGET_WINS ~., data = train_set)
summary(fit1)
```

Looking at the coefficient numbers, we notice something odd. Batting variables that should theoretically have a positive effect on winning like *TEAM_BATTING_H*, *TEAM_BATTING_2B*, *TEAM_BATTING_3B*, and *TEAM_BATTING_HR* have a negative coefficient. This means for every increase in this stat, the lower the less wins - which is odd. We see the inverse for some variables. *TEAM_PITCHING_H* or hits allowed, a stat which has a negative impact on wins, has a positive coefficient. We suspect this is because of the effect of having all the predictor values together.

This model has the most predictive values, contains 12 statistically significant variables, and has a low R squared value.

------------------------------------------------------------------------------------------------------

The second model will contain solely batting variables such as *TEAM_BATTING_H* and *TEAM_BATTING_2B*. Batting statistics can create more points and home runs, therefore increase the chances of a team to win. This can lead to a strong predictive.
```{r}
#second model with just batting variables
fit2 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_SO, data = train_set)
summary(fit2)
```

Unlike the first model where some of the batting variables had negative coefficients, most of them are positive here - which matches the effect that they have on a game. 

Overall this has less predictor values compared to model 1, is comprised mainly of statistically significant variables, but has a lower R squared compared to model 1

-------------------------------------------------------------------------------------------

The third model with contain only pitching and fielding stats. Outside of batting offense, pitching is important because it can limit the scoring of the opposing team. Similarly, the less Fielding Errors - which can give up scoring opportunities - the higher chances of winning. Fielding Double Plays - which is the ability to achieve two outs in a defensive play - can also increase the chances of a win. This model can also potentially give us a high winning percentage.
```{r}
#third model with pitching and fielding variables
fit3 <- lm(TARGET_WINS ~ TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_BB + TEAM_PITCHING_SO + TEAM_FIELDING_E + TEAM_FIELDING_DP, data = train_set)
summary(fit3)
```

The variables *TEAM_PITCHING_H*, *TEAM_PITCHING_HR*, *TEAM_PITCHING_BB* have  positive coefficients which makes sense given that they have a positive effect on wins. *TEAM_FIELDING_E* and *TEAM_PITCHING_SO* are detrimental to a game and so their coefficient is negative. It's odd that *TEAM_FIELDING_DP* is negative because they are a positive occurrence in a game.

This model is comprised mostly of statistically variables, but has the lowest R squared compared to the other models.

### The final model's predicted highest number of wins| SELECT MODELs


### Appendix

```{r}
#All Code will be display here [will update to include all code in this block below]

````



